{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances and Angles between Images\n",
    "\n",
    "We are going to compute distances and angles between images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "By the end of this notebook, you will learn to \n",
    "\n",
    "1. Write programs to compute distance.\n",
    "2. Write programs to compute angle.\n",
    "\n",
    "\"distance\" and \"angle\" are useful beyond their usual interpretation. They are useful for describing __similarity__ between objects. You will\n",
    "first use the functions you wrote to compare MNIST digits. Furthermore, we will use these concepts for implementing the K Nearest Neighbors algorithm, which is a useful algorithm for classifying object according to distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGE: DO NOT EDIT THIS LINE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import sklearn\n",
    "from ipywidgets import interact\n",
    "from load_data import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the MNIST digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST = load_mnist()\n",
    "images = MNIST['data'].astype(np.double)\n",
    "labels = MNIST['target'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figures so that they can be shown in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you need to implement the two functions (`distance` and `angle`) in the cell below which compute the distance and angle between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def distance(x0, x1):\n",
    "    \"\"\"Compute distance between two vectors x0, x1 using the dot product\"\"\"\n",
    "    distance = -1 # <-- EDIT THIS to compute the distance between x0 and x1\n",
    "    return distance\n",
    "\n",
    "def angle(x0, x1):\n",
    "    \"\"\"Compute the angle between two vectors x0, x1 using the dot product\"\"\"\n",
    "    angle = -1 # <-- EDIT THIS to compute angle between x0 and x1\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created some helper functions for you to visualize vectors in the cells below. You do not need to modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vector(v, w):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.gca()\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.grid()\n",
    "    ax.arrow(0, 0, v[0], v[1], head_width=0.05, head_length=0.1, \n",
    "             length_includes_head=True, linewidth=2, color='r');\n",
    "    ax.arrow(0, 0, w[0], w[1], head_width=0.05, head_length=0.1, \n",
    "             length_includes_head=True, linewidth=2, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sanity checks, you may want to have more interesting test cases to test your implementation\n",
    "a = np.array([1,0])\n",
    "b = np.array([0,1])\n",
    "np.testing.assert_almost_equal(distance(a, b), np.sqrt(2))\n",
    "assert((angle(a,b) / (np.pi * 2) * 360.) == 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vector(b, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows some digits from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[labels==0].reshape(-1, 28, 28)[0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have the following questions:\n",
    "\n",
    "1. What does it mean for two digits in the MNIST dataset to be _different_ by our distance function? \n",
    "2. Furthermore, how are different classes of digits different for MNIST digits? Let's find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first question, we can see just how the distance between digits compare among all distances for \n",
    "the first 500 digits. The next cell computes pairwise distances between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for i in range(len(images[:500])):\n",
    "    for j in range(len(images[:500])):\n",
    "        distances.append(distance(images[i], images[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(first=(0, 499), second=(0, 499), continuous_update=False)\n",
    "def show_img(first, second):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    f = images[first].reshape(28, 28)\n",
    "    s = images[second].reshape(28, 28)\n",
    "    \n",
    "    ax0 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax1 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "    \n",
    "    #plt.imshow(np.hstack([f,s]), cmap='gray')\n",
    "    ax0.imshow(f, cmap='gray')\n",
    "    ax1.imshow(s, cmap='gray')\n",
    "    ax2.hist(np.array(distances), bins=50)\n",
    "    d = distance(f.ravel(), s.ravel())\n",
    "    ax2.axvline(x=d, ymin=0, ymax=40000, color='C4', linewidth=4)\n",
    "    ax2.text(0, 46000, \"Distance is {:.2f}\".format(d), size=12)\n",
    "    ax2.set(xlabel='distance', ylabel='number of images')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "def most_similar_image():\n",
    "    \"\"\"Find the index of the digit, among all MNIST digits\n",
    "       that is the second-closest to the first image in the dataset (the first image is closest to itself trivially). \n",
    "       Your answer should be a single integer.\n",
    "    \"\"\"\n",
    "    index = -1 #<-- Change the -1 to the index of the most similar image.\n",
    "    # You should do your computation outside this function and update this number\n",
    "    # once you have computed the result\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = most_similar_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second question, we can compute a `mean` image for each class of image, i.e. we compute mean image for digits of `1`, `2`, `3`,..., `9`, then we compute pairwise distance between them. We can organize the pairwise distances in a 2D plot, which would allow us to visualize the dissimilarity between images of different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the mean for digits of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for n in np.unique(labels):\n",
    "    means[n] = np.mean(images[labels==n], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pair of classes, we compute the pairwise distance and \n",
    "store them into MD (mean distances). We store the angles between the mean digits in AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MD = np.zeros((10, 10))\n",
    "AG = np.zeros((10, 10))\n",
    "for i in means.keys():\n",
    "    for j in means.keys():\n",
    "        MD[i, j] = distance(means[i], means[j])\n",
    "        AG[i, j] = angle(means[i].ravel(), means[j].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the distances! Here we put the pairwise distances. The colorbar\n",
    "shows how the distances map to color intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "grid = ax.imshow(MD, interpolation='nearest')\n",
    "ax.set(title='Distances between different classes of digits',\n",
    "       xticks=range(10), \n",
    "       xlabel='class of digits',\n",
    "       ylabel='class of digits',\n",
    "       yticks=range(10))\n",
    "fig.colorbar(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for the angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "grid = ax.imshow(AG, interpolation='nearest')\n",
    "ax.set(title='Angles between different classes of digits',\n",
    "       xticks=range(10), \n",
    "       xlabel='class of digits',\n",
    "       ylabel='class of digits',\n",
    "       yticks=range(10))\n",
    "fig.colorbar(grid)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "\n",
    "In this section, we will explore the [KNN classification algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\n",
    "A classification algorithm takes input some data and use the data to \n",
    "determine which class (category) this piece of data belongs to.\n",
    "\n",
    "![flower](https://archive.ics.uci.edu/ml/assets/MLimages/Large53.jpg)\n",
    "\n",
    "As a motivating example, consider the [iris flower dataset](https://archive.ics.uci.edu/ml/datasets/iris). The dataset consists\n",
    "of 150 data points where each data point is a feature vector $\\boldsymbol x \\in \\mathbb{R}^4$ describing the attribute of a flower in the dataset, the four dimensions represent \n",
    "\n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "3. petal length in cm \n",
    "4. petal width in cm \n",
    "\n",
    "\n",
    "and the corresponding target $y \\in \\mathbb{Z}$ describes the class of the flower. It uses the integers $0$, $1$ and $2$ to represent the 3 classes of flowers in this dataset.\n",
    "\n",
    "0. Iris Setosa\n",
    "1. Iris Versicolour \n",
    "2. Iris Virginica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "iris = datasets.load_iris()\n",
    "print('data shape is {}'.format(iris.data.shape))\n",
    "print('class shape is {}'.format(iris.target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplicity of the exercise, we will only use the first 2 dimensions (sepal length and sepal width) of as features used to classify the flowers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2] # use first two version for simplicity\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a scatter plot of the dataset below. The x and y axis represent the sepal length and sepal width of the dataset, and the color of the points represent the different classes of flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "iris = datasets.load_iris()\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000',  '#00FF00', '#0000FF'])\n",
    "\n",
    "K = 3\n",
    "x = X[-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "for i, iris_class in enumerate(['Iris Setosa', 'Iris Versicolour', 'Iris Virginica']):\n",
    "    idx = y==i\n",
    "    ax.scatter(X[idx,0], X[idx,1], \n",
    "               c=cmap_bold.colors[i], edgecolor='k', \n",
    "               s=20, label=iris_class);\n",
    "ax.set(xlabel='sepal length (cm)', ylabel='sepal width (cm)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind a KNN classifier is pretty simple: Given a training set $\\boldsymbol X \\in \\mathbb{R}^{N \\times D}$ and $\\boldsymbol y \\in \\mathbb{Z}^N$, we predict the label of a new point $\\boldsymbol x \\in \\mathbb{R}^{D}$ __as the label of the majority of its \"K nearest neighbor\"__ (hence the name KNN) by some distance measure (e.g the Euclidean distance).\n",
    "Here, $N$ is the number of data points in the dataset, and $D$ is the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def pairwise_distance_matrix(X, Y):\n",
    "    \"\"\"Compute the pairwise distance between rows of X and rows of Y\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    X: ndarray of size (N, D)\n",
    "    Y: ndarray of size (M, D)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    distance_matrix: matrix of shape (N, M), each entry distance_matrix[i,j] is the distance between\n",
    "    ith row of X and the jth row of Y (we use the dot product to compute the distance).\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    M, _ = Y.shape\n",
    "    distance_matrix = np.zeros((N, M)) # <-- EDIT THIS to compute the correct distance matrix.\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `pairwise_distance_matrix`, you may be tempting to iterate through\n",
    "rows of $\\boldsymbol X$ and $\\boldsymbol Y$ and fill in the distance matrix, but that is slow! Can you\n",
    "think of some way to vectorize your computation (i.e. make it faster by using numpy/scipy operations only)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def KNN(k, X, y, x):\n",
    "    \"\"\"K nearest neighbors\n",
    "    k: number of nearest neighbors\n",
    "    X: training input locations\n",
    "    y: training labels\n",
    "    x: test input\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    num_classes = len(np.unique(y))\n",
    "    dist = np.zeros(N) # <-- EDIT THIS to compute the pairwise distance matrix\n",
    "\n",
    "    # Next we make the predictions\n",
    "    ypred = np.zeros(num_classes)\n",
    "    classes = y[np.argsort(dist)][:k] # find the labels of the k nearest neighbors\n",
    "    for c in np.unique(classes):\n",
    "        ypred[c] = 0  # <-- EDIT THIS to compute the correct prediction\n",
    "        \n",
    "    return np.argmax(ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the \"decision boundary\" of the KNN classifier, which is the region of a problem space in which the output label of a classifier is ambiguous. This would help us develop an intuition of how KNN behaves in practice. The code below plots the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "step = 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, step),\n",
    "                     np.arange(y_min, y_max, step))\n",
    "\n",
    "ypred = []\n",
    "for data in np.array([xx.ravel(), yy.ravel()]).T:\n",
    "    ypred.append(KNN(K, X, y, data.reshape(1,2)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "ax.pcolormesh(xx, yy, np.array(ypred).reshape(xx.shape), cmap=cmap_light)\n",
    "ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap_bold, edgecolor='k', s=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "mathematics-machine-learning-pca",
   "graded_item_id": "kGOjp",
   "launcher_item_id": "Myc4L"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
